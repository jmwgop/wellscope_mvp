#!/usr/bin/env python3
"""
Analyze Clustering Experiment Results
=====================================

This script analyzes the results from experiment_clustering.py and provides
actionable recommendations for updating your clustering defaults.

Usage:
    python scripts/analyze_experiment_results.py
"""

import json
import pandas as pd
from pathlib import Path

def main():
    # Get project root directory
    project_root = Path(__file__).parent.parent
    
    # Find the most recent experiment results in project root
    experiment_files = list(project_root.glob('clustering_experiment_*.json'))
    if not experiment_files:
        print("‚ùå No experiment results found. Run scripts/experiment_clustering.py first.")
        return
    
    latest_file = max(experiment_files, key=lambda p: p.stat().st_mtime)
    print(f"üìä Analyzing results from: {latest_file}")
    
    try:
        with open(latest_file) as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        print(f"‚ùå Error reading JSON file: {e}")
        print("The experiment results file may be corrupted or incomplete.")
        return
    
    print("\n" + "="*60)
    print("üéØ CLUSTERING EXPERIMENT ANALYSIS")
    print("="*60)
    
    # Dataset info
    dataset_info = data['dataset_info']
    print(f"\nüìà Dataset: {dataset_info['n_wells']} wells, {dataset_info['n_features']} features")
    
    similarity_stats = dataset_info['similarity_stats']
    print(f"üîç Similarity Analysis:")
    print(f"   ‚Ä¢ Average cosine similarity: {similarity_stats['cosine_mean']:.1%}")
    print(f"   ‚Ä¢ This is VERY high similarity - explains why you got only 1 cluster")
    print(f"   ‚Ä¢ Wells are genuinely similar, not a parameter problem!")
    
    # Analyze results
    results = data['results']
    successful_results = [r for r in results if r['success'] and r['n_clusters'] > 1]
    
    print(f"\n‚úÖ Successful Methods: {len(successful_results)} out of {len(results)} tested")
    
    if not successful_results:
        print("\n‚ùå No successful clustering methods found multiple clusters.")
        print("Your wells are genuinely very similar (>90% similarity).")
        return
    
    # Top performers by silhouette score
    scored_results = [r for r in successful_results if r['silhouette_score'] is not None]
    top_results = sorted(scored_results, key=lambda x: x['silhouette_score'], reverse=True)[:10]
    
    print(f"\nüèÜ TOP 10 CLUSTERING SOLUTIONS:")
    print("-" * 80)
    print(f"{'Method':<25} {'Clusters':<9} {'Noise':<6} {'Silhouette':<11} {'Notes'}")
    print("-" * 80)
    
    for i, result in enumerate(top_results, 1):
        method = result['method'][:24]
        n_clusters = result['n_clusters']
        n_noise = result['n_noise']
        sil_score = result['silhouette_score']
        notes = result.get('notes', '')[:20]
        
        print(f"{method:<25} {n_clusters:<9} {n_noise:<6} {sil_score:<11.3f} {notes}")
    
    # Best method analysis
    best_result = top_results[0]
    print(f"\nüéñÔ∏è  BEST METHOD: {best_result['method']}")
    print(f"   ‚Ä¢ Method type: {best_result['method'].split('_')[0]}")
    print(f"   ‚Ä¢ Parameters: {best_result['params']}")
    print(f"   ‚Ä¢ Results: {best_result['n_clusters']} clusters, {best_result['n_noise']} noise wells")
    print(f"   ‚Ä¢ Silhouette score: {best_result['silhouette_score']:.3f} (excellent!)")
    
    # Method type analysis
    method_types = {}
    for result in successful_results:
        method_type = result['method'].split('_')[0]
        if method_type not in method_types:
            method_types[method_type] = []
        method_types[method_type].append(result)
    
    print(f"\nüìä METHOD TYPE PERFORMANCE:")
    for method_type, results_list in sorted(method_types.items()):
        valid_results = [r for r in results_list if r['silhouette_score'] is not None]
        if valid_results:
            avg_sil = sum(r['silhouette_score'] for r in valid_results) / len(valid_results)
            best_sil = max(r['silhouette_score'] for r in valid_results)
            print(f"   ‚Ä¢ {method_type}: {len(results_list)} variants, avg sil={avg_sil:.3f}, best={best_sil:.3f}")
    
    # Generate specific recommendations
    print(f"\nüí° SPECIFIC RECOMMENDATIONS FOR YOUR EAGLEFORD DATA:")
    print("-" * 60)
    
    if best_result['method'].startswith('DBSCAN'):
        params = best_result['params']
        print(f"üéØ Use DBSCAN with these parameters:")
        print(f"   ‚Ä¢ eps = {params['eps']}")
        print(f"   ‚Ä¢ min_samples = {params['min_samples']}")
        print(f"   ‚Ä¢ This gives you {best_result['n_clusters']} meaningful clusters")
        
    elif best_result['method'].startswith('Agg'):
        params = best_result['params']
        print(f"üéØ Use Agglomerative Clustering:")
        print(f"   ‚Ä¢ n_clusters = {params['n_clusters']}")
        print(f"   ‚Ä¢ linkage = '{params['linkage']}'")
        
    elif best_result['method'].startswith('KMeans'):
        params = best_result['params']
        print(f"üéØ Use K-Means (forced separation):")
        print(f"   ‚Ä¢ n_clusters = {params['n_clusters']}")
        print(f"   ‚Ä¢ This forces separation of similar wells")
    
    # Alternative recommendations
    print(f"\nüîÑ ALTERNATIVE APPROACHES:")
    for i, result in enumerate(top_results[1:4], 2):
        method_type = result['method'].split('_')[0]
        print(f"   {i}. {method_type}: {result['n_clusters']} clusters (sil={result['silhouette_score']:.3f})")
    
    # Implementation recommendations
    print(f"\nüõ†Ô∏è  IMPLEMENTATION RECOMMENDATIONS:")
    print(f"1. üîß Update your clustering_intelligence.py:")
    print(f"   ‚Ä¢ For high-similarity datasets (cosine_sim > 0.85):")
    if best_result['method'].startswith('DBSCAN'):
        print(f"   ‚Ä¢ Use eps={best_result['params']['eps']}, min_samples={best_result['params']['min_samples']}")
    
    print(f"\n2. üé® Add UI options:")
    print(f"   ‚Ä¢ Add 'Force Separation' mode that uses K-means")
    print(f"   ‚Ä¢ Show similarity statistics to users")
    print(f"   ‚Ä¢ Warn when wells are >85% similar")
    
    print(f"\n3. üìà For your current Eagleford dataset:")
    print(f"   ‚Ä¢ Your wells ARE genuinely very similar ({similarity_stats['cosine_mean']:.1%} avg similarity)")
    print(f"   ‚Ä¢ Getting 1 cluster was actually correct behavior")
    if best_result['method'].startswith('DBSCAN'):
        print(f"   ‚Ä¢ But DBSCAN with eps={best_result['params']['eps']} finds {best_result['n_clusters']} subtle groups")
    
    print(f"\nüéâ CONCLUSION:")
    print(f"Your clustering wasn't broken - your Eagleford wells are just very similar!")
    print(f"Use the recommended parameters above to find meaningful subtle differences.")
    
    # Generate code snippet for UI
    print(f"\nüìù CODE FOR CLUSTERING_INTELLIGENCE.PY:")
    print("```python")
    print("# Add this to handle high-similarity datasets")
    print("def get_high_similarity_params(similarity_mean: float) -> dict:")
    print("    if similarity_mean > 0.85:")
    if best_result['method'].startswith('DBSCAN'):
        print(f"        return {{'eps': {best_result['params']['eps']}, 'min_samples': {best_result['params']['min_samples']}}}")
    print("    return None")
    print("```")
    
    # Save summary report to project root
    summary_file = project_root / f"clustering_analysis_{data['session_id']}.md"
    generate_markdown_report(data, best_result, top_results, summary_file)
    print(f"\nüìÑ Detailed analysis saved to: {summary_file}")

def generate_markdown_report(data: dict, best_result: dict, top_results: list, output_file: Path):
    """Generate a detailed markdown report of the clustering analysis."""
    
    report = f"""# Clustering Analysis Report

**Session:** {data['session_id']}  
**Generated:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

## Dataset Overview

- **Wells:** {data['dataset_info']['n_wells']}
- **Features:** {data['dataset_info']['n_features']} production months
- **Average Similarity:** {data['dataset_info']['similarity_stats']['cosine_mean']:.1%}

## Key Findings

üéØ **Best Solution:** {best_result['method']}
- **Clusters:** {best_result['n_clusters']}
- **Noise Wells:** {best_result['n_noise']}
- **Silhouette Score:** {best_result['silhouette_score']:.3f}
- **Parameters:** `{best_result['params']}`

## Top Clustering Methods

| Rank | Method | Clusters | Noise | Silhouette | Parameters |
|------|--------|----------|-------|------------|------------|
"""
    
    for i, result in enumerate(top_results[:5], 1):
        method = result['method']
        params_str = str(result['params'])[:50] + "..." if len(str(result['params'])) > 50 else str(result['params'])
        report += f"| {i} | {method} | {result['n_clusters']} | {result['n_noise']} | {result['silhouette_score']:.3f} | `{params_str}` |\n"
    
    report += f"""
## Recommendations

### Immediate Action
1. **Try these parameters in your Streamlit app:**
"""
    
    if best_result['method'].startswith('DBSCAN'):
        report += f"""   - Method: DBSCAN
   - eps: {best_result['params']['eps']}
   - min_samples: {best_result['params']['min_samples']}
"""
    elif best_result['method'].startswith('KMeans'):
        report += f"""   - Method: K-Means  
   - n_clusters: {best_result['params']['n_clusters']}
"""

    report += f"""
### Code Changes

Add to `app/utils/clustering_intelligence.py`:

```python
def handle_high_similarity_data(similarity_mean: float) -> dict:
    \"\"\"Handle high-similarity datasets with specialized parameters.\"\"\"
    if similarity_mean > 0.85:
        return {best_result['params']}
    return None
```

### Why This Works

Your Eagleford wells have {data['dataset_info']['similarity_stats']['cosine_mean']:.1%} average similarity, which is extremely high. This explains why standard clustering parameters only found 1 cluster - the wells are genuinely very similar in their production behavior.

The recommended parameters are specifically tuned to find subtle differences in high-similarity datasets.
"""
    
    with open(output_file, 'w') as f:
        f.write(report)

if __name__ == '__main__':
    main()